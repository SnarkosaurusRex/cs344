{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SEEY4IC0OEzA"
   },
   "source": [
    "# Homework 4\n",
    "###**Part 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obe0nGnxOEzB"
   },
   "source": [
    "(essay goes here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szml4BNpOEzC"
   },
   "source": [
    "###**Part 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Td7u1awwOEzD"
   },
   "source": [
    "1. Fill in random weights.\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    &\\begin{bmatrix}\n",
    "    w_{i_1,h_1} & w_{i_1,h_2} \\\\\n",
    "    w_{i_2,h_1} & w_{i_2,h_2}\n",
    "    \\end{bmatrix}\n",
    "    \\leftarrow\n",
    "    \\begin{bmatrix}\n",
    "    0.11 & 0.12 \\\\\n",
    "    0.21 & 0.08\n",
    "    \\end{bmatrix} \\\\\n",
    "    &\\begin{bmatrix}\n",
    "    w_{h_1, o_1} \\\\ \n",
    "    w_{h_2, o_1} \n",
    "    \\end{bmatrix}\n",
    "    \\leftarrow\n",
    "    \\begin{bmatrix}\n",
    "    0.14 \\\\\n",
    "    0.15\n",
    "    \\end{bmatrix}\n",
    "    \\\\\\\\\n",
    "    \\end{aligned}$\n",
    "    \n",
    "2. Compute the output for one sample (XOR: `[1, 1]` &rarr; `0`).\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    o_j &= \n",
    "    \\begin{bmatrix}\n",
    "    1 & 1 \\\\ \n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "    \\begin{bmatrix}\n",
    "    0.11 & 0.12 \\\\\n",
    "    0.21 & 0.08\n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "    \\begin{bmatrix}\n",
    "    0.14 \\\\\n",
    "    0.15\n",
    "    \\end{bmatrix}\n",
    "    \\\\ &=\n",
    "    \\begin{bmatrix}\n",
    "    1 * 0.11 + 1 * 0.21 & 1 * 0.12 + 1 * 0.08\n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "    \\begin{bmatrix}\n",
    "    0.14 \\\\ \n",
    "    0.15\n",
    "    \\end{bmatrix}\n",
    "    \\\\ &=\n",
    "    \\begin{bmatrix}\n",
    "    0.32 & 0.20\n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "    \\begin{bmatrix}\n",
    "    0.14 \\\\ \n",
    "    0.15 \n",
    "    \\end{bmatrix}\n",
    "    \\\\ &=\n",
    "    \\begin{bmatrix}\n",
    "    0.32 * 0.14 + 0.20 * 0.15\n",
    "    \\end{bmatrix}\n",
    "    \\\\ &= 0.0748\n",
    "    \\\\\\\\\n",
    "    \\end{aligned}\n",
    "    \\\\\n",
    "    $\n",
    "    \n",
    "3. Compute the error (and more importantly, the delta).\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    L_2Error &= (0 - 0.0748)^2 \\\\\n",
    "    &= 0.0056 \\\\\n",
    "    \\Delta_{o_1} &= (0 - 0.0748) \\\\\n",
    "    &= -0.0748 \\\\\n",
    "    \\\\\n",
    "    \\end{aligned}$\n",
    "    \n",
    "4. Backpropagate updates back through the network, assuming: \n",
    "    $learning\\_rate = 0.05$; \n",
    "    identity function (_f(x) = x_) activation functions for all nodes.\n",
    "     \n",
    "    $\\begin{aligned}\n",
    "    \\begin{bmatrix}\n",
    "    w_{h_1, o_1} \\\\ \n",
    "    w_{h_2, o_1}\n",
    "    \\end{bmatrix} &\\leftarrow \n",
    "    \\begin{bmatrix}\n",
    "    0.14 \\\\ \n",
    "    0.15 \n",
    "    \\end{bmatrix} + 0.05 \\cdot \n",
    "    \\begin{bmatrix}\n",
    "    0.32 \\\\ \n",
    "    0.20 \n",
    "    \\end{bmatrix} \\cdot 1.0 \\cdot -0.0748 \\\\\\\\\n",
    "    &= \n",
    "    \\begin{bmatrix}\n",
    "    0.14 \\\\ \n",
    "    0.15 \n",
    "    \\end{bmatrix} + \n",
    "    \\begin{bmatrix}\n",
    "    0.05 * 0.32 * 1.0 * -0.0748 \\\\\n",
    "    0.05 * 0.20 * 1.0 * -0.0748 \n",
    "    \\end{bmatrix} \\\\\\\\\n",
    "    &= \n",
    "    \\begin{bmatrix}\n",
    "    0.14 \\\\ \n",
    "    0.15 \n",
    "    \\end{bmatrix} +\n",
    "    \\begin{bmatrix}\n",
    "    -0.0012 \\\\\n",
    "    -0.0007 \n",
    "    \\end{bmatrix} \\\\\\\\\n",
    "    &=\n",
    "    \\begin{bmatrix}\n",
    "    0.1388 \\\\ \n",
    "    0.1493\n",
    "    \\end{bmatrix}\n",
    "    \\end{aligned}$\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    \\\\\\begin{bmatrix}\n",
    "    w_{i_1,h_1} & w_{i_1,h_2} \\\\ \n",
    "    w_{i_2,h_1} & w_{i_2,h_2}\n",
    "    \\end{bmatrix}\n",
    "    &\\leftarrow \n",
    "    \\begin{bmatrix}\n",
    "    0.11 & 0.12 \\\\\n",
    "    0.21 & 0.08\n",
    "    \\end{bmatrix} + 0.05 \\cdot\n",
    "    \\begin{bmatrix}\n",
    "    1 & 1 \\\\ \n",
    "    1 & 1\n",
    "    \\end{bmatrix} \\cdot 1.0 \\odot\n",
    "    \\begin{bmatrix}\n",
    "    0.14 & 0.15 \\\\ \n",
    "    0.14 & 0.15\n",
    "    \\end{bmatrix} \\cdot -0.0748 \\\\\\\\\n",
    "    &=\n",
    "    \\begin{bmatrix}\n",
    "    0.11 & 0.12 \\\\\n",
    "    0.21 & 0.08\n",
    "    \\end{bmatrix} + \n",
    "    \\begin{bmatrix}\n",
    "    0.05 * 1 * 1.0 & 0.05 * 1 * 1.0 \\\\ \n",
    "    0.05 * 1 * 1.0 & 0.05 * 1 * 1.0 \\\\ \n",
    "    \\end{bmatrix} \\odot \n",
    "    \\begin{bmatrix}\n",
    "    0.14 * -0.0748 & 0.15 * -0.0748\\\\ \n",
    "    0.14 * -0.0748 & 0.15 * -0.0748 \n",
    "    \\end{bmatrix} \\\\\\\\\n",
    "    &=\n",
    "    \\begin{bmatrix}\n",
    "    0.11 & 0.12 \\\\\n",
    "    0.21 & 0.08\n",
    "    \\end{bmatrix} + \n",
    "    \\begin{bmatrix}\n",
    "    0.05 & 0.05 \\\\ \n",
    "    0.05 & 0.05 \n",
    "    \\end{bmatrix} \\odot \n",
    "    \\begin{bmatrix}\n",
    "    -0.0105 & -0.0112 \\\\\n",
    "    -0.0105 & -0.0112\n",
    "    \\end{bmatrix} \\\\\\\\\n",
    "    &=\n",
    "    \\begin{bmatrix}\n",
    "    0.11 & 0.12 \\\\\n",
    "    0.21 & 0.08\n",
    "    \\end{bmatrix} + \n",
    "    \\begin{bmatrix}\n",
    "    0.05 * -0.0105 & 0.05 * -0.0112 \\\\\n",
    "    0.05 * -0.0105 & 0.05 * -0.0112\n",
    "    \\end{bmatrix} \\\\\\\\\n",
    "    &=\n",
    "    \\begin{bmatrix}\n",
    "    0.11 & 0.12 \\\\\n",
    "    0.21 & 0.08\n",
    "    \\end{bmatrix} +     \n",
    "    \\begin{bmatrix}\n",
    "    -0.00053 & -0.00056 \\\\\n",
    "    -0.00053 & -0.00056\n",
    "    \\end{bmatrix} \\\\\\\\\n",
    "    &= \n",
    "    \\begin{bmatrix}\n",
    "    0.10947 & 0.11944 \\\\\n",
    "    0.20947 & 0.07944\n",
    "    \\end{bmatrix}  \n",
    "    \\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RPsg3OerOEzD"
   },
   "source": [
    "###**Part 3**\n",
    "Build a Keras-based ConvNet for Kerasâ€™s Fashion MNIST dataset (fashion_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "colab_type": "code",
    "id": "RftBHRE7OEzE",
    "outputId": "bd20bf21-3165-4231-84b6-2c435328b9bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''Based on kvlinden's keras-cnn.ipynb'''\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "VaCp_VrHOEzH",
    "outputId": "bd858fc6-f066-48fe-dd00-b2248597fb4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 4us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Retrieve/set up the datasets\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "47miOzUdOEzL",
    "outputId": "8aadb3f2-a7cc-4831-8574-da3499f52881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.5527 - acc: 0.7945\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.3432 - acc: 0.8744\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.2888 - acc: 0.8946\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.2560 - acc: 0.9056\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.2325 - acc: 0.9141\n",
      "10000/10000 [==============================] - 3s 347us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2780694966673851, 0.8945]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/evaluate the model - rmsprop version\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "S0c8nnzXQ5o2",
    "outputId": "d701fda3-5870-49ff-a793-01c2ff3c86a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1833 - acc: 0.9337\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1744 - acc: 0.9369\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1705 - acc: 0.9379\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1674 - acc: 0.9395\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1644 - acc: 0.9407\n",
      "10000/10000 [==============================] - 3s 346us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24643010388612746, 0.9117]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/evaluate the model - stochastic gradient descent version\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "-pXgLn8vSwLk",
    "outputId": "b001ac4d-53c3-41a2-a0f4-20fc9666ab2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.2054 - acc: 0.9297\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1583 - acc: 0.9427\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1462 - acc: 0.9470\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1377 - acc: 0.9507\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1307 - acc: 0.9537\n",
      "10000/10000 [==============================] - 4s 355us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24923378205299376, 0.9156]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/evaluate the model - adagrad version\n",
    "\n",
    "model.compile(optimizer='adagrad',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "DHcP11OVU6RR",
    "outputId": "cc5cbb1c-d84c-469a-bfa4-29dfe06ada62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1767 - acc: 0.9348\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1646 - acc: 0.9387\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1501 - acc: 0.9430\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1380 - acc: 0.9483\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1268 - acc: 0.9524\n",
      "10000/10000 [==============================] - 4s 359us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27405011996626855, 0.9068]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/evaluate the model - adam version\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above results, the model that uses the AdaGrad optimizer is the most performant (highest accuracy, lowest loss)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
